\chapter{ПОСТАНОВКА ЗАДАЧИ В ОТСУТСТВИЕ МОДЕЛИ СИСТЕМЫ}\label{chap3}
В данной главе мы рассматриваем задачу из предыдущей главы в условии отсутствия заранее известной реализации системы в пространстве состояний. Классический подход в подобных ситуациях состоит в предварительной идентификации системы %TODO refs 
и последующем решении задачи уже имеющимся способом, основанным на знании модели. Однако, такой подход не всегда целесообразен.
%TODO refs
Нами будет предложен альтернативный способ, не нуждающийся в явном параметрическом представлении системы вовсе. Основой нам послужит поведенческий подход к динамическим системам, изложенный в главе \ref{chap1}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Постановка задачи по сгенерированным данным}\label{2sec:data-driven-approach} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Будем считать, что наши сведения о линейной системе $G$ сводятся к верхней оценке её размерности $n$ и одной предварительно сгенерированной траектории $\{u^d(t), y^d(t)\}_{t = 0}^{T^d - 1}$, причём эта траектория измерена точно. Что до траекторий $\{u(0), u(1), \ldots, u(\tau-1), y(0), y(1), \ldots, y(\tau-1)\} = \{u_\tau, y_\tau \}$ в момент $\tau$ в процессе управления системой, их будем считать известными с точностью до ограниченной ошибки: нам доступны лишь $\{u_\tau, \tilde{y}_\tau\}$, где $\tilde{y}(t) = y(t) + \xi(t), t = 0,  \ldots, \tau -1$.

Задачей, подобно предыдущему пункту, ставится минимизация квадратичного критерия качества 
$$\sum_{\tau = t}^{T-1} \norm{u(t)}^2$$ 
при гарантированном соблюдении линейных условий 
$$G(t)y(t) \leq g(t), \quad u_{min} \leq u(t) \leq u_{max}, t \leq \tau \leq T-1$$
на входные и выходные сигналы, где $$t$$ --- момент начала контроля системы.


\bigskip
Продемонстрируем, как априорная траектория $\{u^d, y^d\}$ при определённых условиях может иметь ту же информационную ценность, что и модель системы, в случае её наличия.

Теорема \ref{fundamental theorem} в непосредственно приведённой формулировке позволяет проверять любую траекторию фиксированной длины на принадлежность системе. В нашем случае стоит обратная задача: дабы определить, допустимо ли конкретное управляющее воздействие в конкретный момент времени, хотелось бы уметь в некотором смысле симулировать систему.

Модификацию \ref{fundamental theorem} можно использовать для генерации множества возможных траекторий $\{u_T, y_T\}$ длины $T$ с некоторой фиксированной начальной частью $\{u^p_\tau, y^p_\tau\}$, которую мы будем именовать "прошлой" частью длины $\tau$. Нефиксированную часть траектории $\{u(\tau), \ldots, u(T-1), y(\tau), \ldots, y(T-1)\}$ будем обозначать $\{u_\tau^f, y_\tau^f\}$, и обращаться к ней как к "будущей" части траектории. 
Соответствующим образом будем делить на "прошлое" и "будущее" для момента $\tau$ и компоненты векторов $u, y$
$$u = \begin{pmatrix}u(0) \\
\vdots \\
u(\tau-1) \\
 \hline 
u(\tau)\\
\vdots \\
u(T-1)
\end{pmatrix} = 
\begin{pmatrix}
u_{\tau}^p \\
\hline
 u_{\tau}^f
\end{pmatrix},\quad y = \begin{pmatrix}y(0) \\
	\vdots \\
	y(\tau-1) \\
 	\hline 
	y(\tau)\\
	\vdots \\
	y(T-1)
	\end{pmatrix} = 
	\begin{pmatrix}
	y_{\tau}^p \\
	\hline
 	y_{\tau}^f
	\end{pmatrix},$$
и строки матриц Ганкеля для априорной траектории
\begin{equation}
H_T(u^d) = \begin{pmatrix}
  u^d(0) & \cdots & u^d(T^d-T)\\
  \vdots & \ddots & \vdots \\
  u^d(\tau-1) & \cdots & u(\tau-1 + T^d - T) \\
  \hline
  u^d(\tau) & \cdots & u(\tau + T^d-T)\\
  \vdots & \ddots & \vdots \\
  u^d(T-1) & \cdots & u^d(T^d-1)
\end{pmatrix} = 
		\begin{pmatrix}
		U_{\tau}^p \\
		U_{\tau}^f
		\end{pmatrix},  
\end{equation}
\begin{equation}
H_T(y^d) = \begin{pmatrix}
  y^d(0) & \cdots & y^d(T^d-T)\\
  \vdots & \ddots & \vdots \\
  y^d(\tau-1) & \cdots & y(\tau-1 + T^d - T) \\
  \hline
  y^d(\tau) & \cdots & y(\tau + T^d-T)\\
  \vdots & \ddots & \vdots \\
  y^d(T-1) & \cdots & y^d(T^d-1)
\end{pmatrix} = 
		\begin{pmatrix}
		Y_{\tau}^p \\
		Y_{\tau}^f
		\end{pmatrix},  
\end{equation}

Согласно теореме \ref{trajectory check}, $\{u_{\tau}^p, u_{\tau}^f, y_{\tau}^p, y_{\tau}^f\}$ является траекторией системы $G$ тогда и только тогда, когда у уравнения 
\begin{equation}\label{traj-cond}
\begin{pmatrix}
U_{\tau}^p \\
Y_{\tau}^p \\
U_{\tau}^f \\
Y_{\tau}^f
\end{pmatrix} \alpha = \begin{pmatrix}
u_{\tau}^p \\
y_{\tau}^p \\
u_{\tau}^f \\
y_{\tau}^f
\end{pmatrix}
\end{equation}
есть решение $\alpha \in \mathbb{R}^{T^d - T +1}$.
Посемy для построения возможных траекторий можно воспользоваться следующим алгоритмом.\\
Шаг 1. Найти некоторое решение системы линейных алгебраических уравнений
\begin{equation}
\begin{pmatrix}
U_{\tau}^p \\
Y_{\tau}^p \\
U_{\tau}^f 
\end{pmatrix} \alpha = \begin{pmatrix}
u_{\tau}^p \\
y_{\tau}^p \\
u_{\tau}^f 
\end{pmatrix}
\end{equation}
Шаг 2. Вычислить $y_{\tau}^f = Y_{\tau}^f \alpha$. Получили одну из возможных траекторий.

\begin{remark}
Очевидно, множество решений $\alpha$ всегда не пусто, а вот для единственности решения, которая представляет особый практический интерес, нужно наложить некоторые условия. Поскольку для линейной системы размерности $n$ траектория длины $n$ однозначно определяет начальное состояние, то для обеспечения единственности достаточно потребовать $\tau \geq n$. Потому в дальнейшем полагаем, что начало управления $t \geq n$ --- это своего рода неявный аналог явного граничения $x_0 \in X_0$ в постановке задачи при известной модели.
\end{remark}

Таким образом, вместо явного задания динамики системы моделью в пространстве состояний, мы пользуемся неявным описанием вида \ref{traj-cond} поведения системы, начальное состояние системы также в нашем случае фиксируется неявно.

\bigskip
Используем ту же стратегию управления, что и в предыдущем пункте, а именно, в каждый момент времени $t \leq \tau \leq T$ мы решаем следующую задачу оптимального управления по разомкнутому контуру:
\begin{equation}\label{dd-oc-at-tau}
\min\limits_u u^Tu 
\end{equation}
\begin{equation}
\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
\end{pmatrix} \alpha = \begin{pmatrix}
u_\tau^p \\
y_\tau^p \\
u \\
\end{pmatrix}
\end{equation}
\begin{equation}
\tilde{y}_\tau^p = y_\tau^p + \xi_\tau,
\end{equation}
\begin{equation}
G_\tau Y_\tau^f \alpha \leq g_\tau \quad \forall \alpha, \quad -\varepsilon\mathbbm{1} \leq \xi_\tau \leq \varepsilon \mathbbm{1},
\end{equation}
где матрица 
\[
G_\tau = 
\begin{pmatrix}
  \begin{matrix}
  G(\tau)
  \end{matrix}
  & \rvline & \bigzero & \rvline & \cdots & \rvline & \bigzero\\
\hline
  \bigzero & \rvline &
  \begin{matrix}
    G(\tau + 1)
  \end{matrix}
  & \rvline & \cdots  & \rvline & \bigzero \\
\hline
  \vdots & \rvline & \vdots & \rvline & 
  \begin{matrix}
    \ddots
  \end{matrix} 
  & \rvline & \bigzero \\
\hline
  \bigzero & \rvline & \bigzero & \rvline & \bigzero & \rvline &
  \begin{matrix}
    G(T-1)
  \end{matrix}
\end{pmatrix},
\]
вектор $g_{\tau} = (g(\tau), g(\tau+1), \cdots, g(T-1)).$ 

Из полученного в момент $\tau$ оптимального управляющего воздействия $u^0 = (u^0(\tau), u^0(\tau+1), \ldots, u^0(T-1))$ мы применяем к системе $u^p(\tau) = u^0(\tau).$ Переходим к решению задачи \ref{dd-oc-at-tau} в момент $\tau+1$, зная траекторию $\{u^p_{\tau+1}, \tilde{y}^p_{\tau+1}\}$. Таким образом, если существовало допустимое воздействие в момент $\tau$, то гарантировано существует допустимое воздействие в момент $\tau + 1$, причём значение критерия качества на каждом шагу не увеличивается.

Многообещающим выглядит разделение наблюдения и управления, использованное в предыдущем разделе. Продемонстрируем, как элегантно реализуется принцип разделения в поведенческой манере.
\begin{lemma}\label{dd-separation}
Пусть $\{u_{\tau}^p, y_{\tau}^p \}$--некоторая траектория системы \ref{model} длины $\tau \geq n$. Тогда любая траектория $\{u_{\tau}^p, u, y_{\tau}^p, y\}$ длины $T$ системы \ref{model} однозначно представима в виде суммы траекторий $\{0, u, 0, y_0\}$ и $\{u_{\tau}^p, 0, y_{\tau}^p, \hat{y}\}$ длины $T$, причём определить неизвестные участки $y_0, \hat{y}$ можно следующим образом:
Шаг 1. Найти некоторое решение алгебраичеких уравнений
\begin{equation}
\begin{pmatrix}                     
U_\tau^p \\                         
Y_\tau^p \\
U_\tau^f \\
\end{pmatrix} \hat{\alpha} = \begin{pmatrix}
u_\tau^p \\
y_\tau^p \\
0 \\
\end{pmatrix}, \quad
\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
\end{pmatrix} \alpha_0 = \begin{pmatrix}
0 \\
0 \\
u \\
\end{pmatrix}
\end{equation}
Шаг 2. Вычислить $\hat{y} = Y_\tau^f\hat{\alpha}, $ $y_0 = Y_\tau^f\alpha_0$
\end{lemma}

\begin{proof}
Поскольку длина $\tau$ исходной траектории не меньше размерности системы $n$, то, как уже было показано выше, однозначно определены выходы системы $\hat{y}, y_0$ для входных сигналов $0, u$ соответственно, причём $\hat{y}$ соответствует выходной траектории неуправляемой с момента $\tau$ системы, а $y_0$ -- номинальной выходной траектории из нулевого состояния в момент $\tau$ (нулевое состояние в момент $\tau$  неявно задают $\{u_\tau^p, y_\tau^p\} = \{0, 0\}$ --- именно такую траекторию имеет система с нулевым начальным состоянием, а значит, и с нулевым состоянием в момент $ \tau$; с другой стороны, $\tau \geq n$ обеспечивает единственность этой траектории). 
\end{proof}

В связи с вышеизложенным, ограничение на выходные сигналы принимает вид
$G_{\tau}(y_0+\hat{y}) \leq g_{\tau}$. Наложим на $y_0$ более жёсткое условие: $G_{\tau}y_0 \leq g_{\tau}-\chi(\tau)$, где $\chi_i(\tau)$ соответствует наихудшей реализации состояния системы в момент $\tau$, а именно является решением задачи \ref{estimation} линейного программирования.
\begin{equation} \label{estimation}
\chi_i(\tau) = \max\limits_{\hat{\alpha}, \xi_{\tau}} G_{\tau i}\hat{y}
\end{equation}
$$\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
Y_\tau^f \\
\end{pmatrix} \hat{\alpha} = \begin{pmatrix}
u_\tau^p \\
\tilde{y}_\tau^p + \xi_{\tau}\\
0 \\
\hat{y}\\
\end{pmatrix}
$$
$$-\varepsilon \mathbbm{1} \leq \xi_{\tau} \leq \varepsilon \mathbbm{1}$$
Что, в более компактной формулировке, являет собой задачу
\begin{equation} \label{estimation-lp}
\chi_i(\tau) = \max\limits_{\hat{\alpha}} G_{\tau i}Y_{\tau}^f\hat{\alpha}
\end{equation}
$$\begin{pmatrix}
U_\tau^p \\
U_\tau^f \\
\end{pmatrix} \hat{\alpha} = \begin{pmatrix}
u_\tau^p \\
0 \\
\end{pmatrix}
$$
$$
\tilde{y}_{\tau}-\varepsilon \mathbbm{1} \leq 
Y_\tau^p \hat{\alpha} \leq 
\tilde{y}_\tau + \varepsilon \mathbbm{1}
$$
Удовлетворение $y_0$ ужесточённого ограничения автоматически влечёт удовлетворение исходного ограничения для любой возможной реализации $\hat{y}$.
\bigskip

\begin{definition}
\textit{Уровнем ошибки} в задаче \ref{estimation-lp} будем называть $\varepsilon$, а \textit{номинальной задачей наблюдения при уровне ошибки} $\varepsilon$ будем называть задачу \ref{estimation-lp} для истинной траектории, т.е. для случая $\tilde{y}_\tau = y_\tau.$
\end{definition}
Очевидно, если задача \ref{estimation-lp} разрешима при любой покомпонентно ограниченной $\varepsilon$ ошибке, то должна быть разрешима номинальная задача. Ещё один результат, касающийся вопроса гарантированной разрешимости приведём ниже.
\begin{lemma}\label{estimation-guarantees}
Если номинальная задача наблюдения при уровне ошибки $\varepsilon$ разрешима, то для любого неточного выходного сигнала $\tilde{y}_\tau = y_\tau + \xi_\tau$, где ошибка ограничена поэлементно $\norm{\xi_\tau}_\infty \leq \frac{\varepsilon}{2}$ соответствующая задача\ref{estimation-lp} также имеет решение.
\end{lemma}
\begin{proof}
Для любого $\tilde{y}_\tau = y_\tau + \xi_\tau$ с ограниченной ошибкой $\norm{\xi_\tau}_\infty \leq \frac{\varepsilon}{2}$ задача \ref{estimation-lp} имеет те же самые целевую функцию и ограничения в виде равенств, а также не менее сильные ограничивающие неравенства: 
$$y_\tau - \varepsilon \mathbbm{1} \leq \tilde{y}_\tau - \frac{\varepsilon}{2}\mathbbm{1} \leq Y_\tau^p\hat{\alpha} \leq \tilde{y}_\tau + \frac{\varepsilon}{2}\mathbbm{1} \leq y_\tau + \varepsilon \mathbbm{1}.$$
\end{proof}


Задача с ужесточёнными условиями на $y_0$ принимает следующий вид

\begin{equation}\label{control}
\min\limits_{\alpha_0}u^Tu
\end{equation} 
$$\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
Y_\tau^f \\
\end{pmatrix} \alpha_0 = \begin{pmatrix}
0 \\
0 \\
u \\
y_0 \\
\end{pmatrix}$$
$$G_{\tau}y_0 \leq g_{\tau} - \chi(\tau)$$


Снова переходим к эквивалентному, но более компактному виду, получаем
\begin{equation}\label{control-qp}
\min\limits_{\alpha_0}\alpha_0^T{U_{\tau}^f}^TU_{\tau}^f\alpha_0
\end{equation} 
$$
\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
\end{pmatrix} \alpha_0 = \begin{pmatrix}
0 \\
0 \\
\end{pmatrix}
$$
$$G_{\tau}Y_{\tau}^f\alpha_0 \leq g_{\tau} - \chi(\tau)$$

Таким образом, задача оптимального управления, решаемая в каждой врменной точке $t \leq \tau \leq T-1$, свелась к нескольким задачам линейного программирования и одной выпуклой задаче квадратичного программирования.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%TODO either complete of delete
\section{Недетерминированный случай: априорные измерения неточны}
Рассмотрим случай, когда и априорные измерения содержат некоторую ошибку, т.е. $\tilde{y}^d = y^d + \xi^d.$

Тогда $\tilde{Y}_{\tau}^p = Y_{\tau}^p + \mathit{\Xi}_{\tau}^p$,
$\tilde{Y}_{\tau}^f = Y_{\tau}^f + \mathit{\Xi}_{\tau}^f$, где 
$$
\begin{pmatrix}
		\mathit{\Xi}_{\tau}^p\\
		\mathit{\Xi}_{\tau}^f
		\end{pmatrix}  = \begin{pmatrix}
  \xi(0) & \cdots & \xi(T^d-T)\\
  \vdots & \ddots & \vdots \\
  \xi(\tau-1) & \cdots & \xi(\tau - 1 + T^d-T) \\
  \hline
  \xi(\tau) & \cdots & y(\tau + T^d-T)\\
  \vdots & \ddots & \vdots \\
  \xi(T-1) & \cdots & y(T^d-1)
\end{pmatrix} 
    = H_T(\xi^d) 
$$

В соответствии с этим наша задача оптимальной оценки \ref{estimation} перепишется как
\begin{equation} \label{estimation-noisy}
\chi_i(\tau) = \max\limits_{\hat{\alpha}, \xi_{\tau}, \xi^d} G_{\tau i}\hat{y}
\end{equation}
$$\begin{pmatrix}
U_\tau^p \\
Y_\tau^p + \mathit{\Xi}_\tau^p\\
U_\tau^f \\
Y_\tau^f + \mathit{\Xi}_\tau^f \\
\end{pmatrix} \hat{\alpha} = \begin{pmatrix}
u_\tau^p \\
y_\tau + \xi_{\tau}\\
0 \\
\hat{y}\\
\end{pmatrix}
$$
$$-\varepsilon \mathbbm{1} \leq \xi_{\tau} \leq \varepsilon \mathbbm{1}$$
$$-\varepsilon \mathbbm{1} \leq \xi^d \leq \varepsilon \mathbbm{1}$$

Эта задача являет собой следующую относительно переменной $\kappa = (\hat{\alpha}, \xi^d)$ задачу с квадратичной целевой функцией и квадратичными ограничениями. 

................................................
................................................
Если будем в принципе включать в работу этот раздел, распишу подробно все матрицы для этой задачи. Она невыпуклая, но иногда правдоподобно метод внутренней точки у меня срабатывал.
%TODO write it down in details (if this section is going to be included in the work at all)

%problem is non-convex, but maybe interior-point method might be applicable?

