\chapter{ПОСТАНОВКА ЗАДАЧИ В ОТСУТСТВИЕ МОДЕЛИ СИСТЕМЫ}\label{chap3}
Ниже будет рассмотрена задача из предыдущей главы при условии отсутствия заранее известной реализации системы в пространстве состояний. Классический подход в подобных ситуациях состоит в предварительной идентификации системы и последующем решении задачи уже имеющимся способом, основанным на знании модели, как в главе \ref{chap2}. Однако, такой подход не всегда целесообразен.

В этой главе будет предложен альтернативный подход, не нуждающийся в явном параметрическом представлении системы вовсе. Основой ему послужит бихевиористский подход к динамическим системам, изложенный в главе \ref{chap1}, а также принцип разделимости управления и наблюдения, уже использовавшийся в главе \ref{chap2}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Постановка и решение задачи по сгенерированным данным}\label{data-driven-approach}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Будем считать, что сведения о линейной системе $G$ сводятся к верхней оценке ее размерности $n$ и одной предварительно сгенерированной траектории $\{u^d(t), y^d(t)\}_{t = 0}^{T^d - 1}$, причем эта траектория измерена точно. 

Как и ранее,  траектории "прошлого"\ ${\{(u^p(0), u^p(1), \ldots, u^p(\tau-1)), (y^p(0), y^p(1), \ldots, y^p(\tau-1))\} = \{u_\tau^p, y_\tau^p \}}$, известные к текущему моменту $\tau$ в процессе управления системой, будем считать измеренными с точностью до ограниченной ошибки: т.е. доступны лишь $\{u_\tau^p, \tilde{y}_\tau^p\}$, где ${\tilde{y}^p_\tau = y^p_\tau + \xi_\tau}$.

В текущий момент времени $\tau$, подобно предыдущей главе, ставится задача минимизация квадратичного критерия качества
$$
    \sum_{t = \tau}^{T-1} \norm{u(t)}^2,
    $$
при гарантированном соблюдении линейных условий
$$
    G(t)y(t) \leq g(t), \quad u_{\min} \leq u(t) \leq u_{\max}, \quad \tau \leq t \leq T-1,
    $$
на входные и выходные сигналы.

Покажем, как априорная траектория $\{u^d, y^d\}$ при определенных условиях может иметь ту же информационную ценность, что и модель системы $(A,B,C,D)$, в случае ее наличия.

Теорема \ref{trajectory check} в непосредственно приведенной формулировке позволяет проверять любую траекторию фиксированной длины на принадлежность множеству траекторий системы. В рассматриваемом случае стоит обратная задача: чтобы определить, допустимо ли конкретное управление в конкретный момент времени, хотелось бы уметь в некотором смысле симулировать систему.

Модификацию теоремы \ref{trajectory check} можно использовать для генерации множества возможных траекторий $\{u^p_\tau, u, y^p_\tau, y\}$ длины $T$ с некоторой фиксированной "прошлой"\ начальной частью $\{u^p_\tau, y^p_\tau\}$ длины $\tau$. Нефиксированную часть ${\{u, y\} = \{u(\tau), \ldots, u(T-1), y(\tau), \ldots, y(T-1)\}}$ будем называть "будущей"\ частью траектории.
Соответственно, будем делить на "прошлое"\ и "будущее"\ для момента $\tau$ и строки матриц Ганкеля для априорной траектории:
\begin{equation}
H_T(u^d) = \begin{pmatrix}
  u^d(0) & \cdots & u^d(T^d-T)\\
  \vdots & \ddots & \vdots \\
  u^d(\tau-1) & \cdots & u^d(\tau-1 + T^d - T) \\
  \hline
  u^d(\tau) & \cdots & u^d(\tau + T^d-T)\\
  \vdots & \ddots & \vdots \\
  u^d(T-1) & \cdots & u^d(T^d-1)
\end{pmatrix} =
		\begin{pmatrix}
		U_{\tau}^p \\
		U_{\tau}^f
		\end{pmatrix},
\end{equation}
\begin{equation}
H_T(y^d) = \begin{pmatrix}
  y^d(0) & \cdots & y^d(T^d-T)\\
  \vdots & \ddots & \vdots \\
  y^d(\tau-1) & \cdots & y^d(\tau-1 + T^d - T) \\
  \hline
  y^d(\tau) & \cdots & y^d(\tau + T^d-T)\\
  \vdots & \ddots & \vdots \\
  y^d(T-1) & \cdots & y^d(T^d-1)
\end{pmatrix} =
		\begin{pmatrix}
		Y_{\tau}^p \\
		Y_{\tau}^f
		\end{pmatrix},
\end{equation}

Если входной сигнал $u^d$ является постоянно возбуждающим порядка ${n + T}$, то, согласно теореме \ref{trajectory check}, $\{u_{\tau}^p, u, y_{\tau}^p, y\}$ является траекторией системы $G$ тогда и только тогда, когда уравнение
\begin{equation}\label{traj-cond}
\begin{pmatrix}
U_{\tau}^p \\
Y_{\tau}^p \\
U_{\tau}^f \\
Y_{\tau}^f
\end{pmatrix} \alpha = \begin{pmatrix}
u_{\tau}^p \\
y_{\tau}^p \\
u \\
y
\end{pmatrix}
\end{equation}
имеет решение $\alpha \in \mathbb{R}^{T^d - T +1}$.
Поэтому для построения возможных траекторий можно воспользоваться следующим алгоритмом:\\
1. Зафиксировать интересующее значение "будущего"\ входного сигнала $u$.\\
2. Для выбранного $u$ найти некоторое решение $\alpha \in \mathbb{R}^{T^d-T+1}$ системы линейных алгебраических уравнений
\begin{equation}
\begin{pmatrix}
U_{\tau}^p \\
Y_{\tau}^p \\
U_{\tau}^f
\end{pmatrix} \alpha = \begin{pmatrix}
u_{\tau}^p \\
y_{\tau}^p \\
u
\end{pmatrix}.
\end{equation}
3. Вычислить $y = Y_{\tau}^f \alpha$. Получили одну из возможных траекторий для фиксированных $u^p_\tau, y^p_\tau, u$.

\begin{remark}
В силу теоремы \ref{trajectory check}, для любых $u^p_\tau, y^p_\tau, u$ хотя бы одну возможную выходную траекторию $y$ мы найти сможем, а вот для единственности $y$, которая представляет особый практический интерес, нужно наложить некоторые условия. Поскольку для линейной системы размерности $n$ траектория длины $n$ однозначно определяет начальное состояние, то для обеспечения единственности достаточно потребовать $\tau \geq n$. Потому в дальнейшем полагаем, что управление начинается в момент $n$, --- это своего рода неявный аналог явного ограничения $x_0 \in X_0$ в постановке задачи при известной модели.
\end{remark}

\begin{remark}\label{lower bound on T^d}
Чем больше горизонт планирования $T$, тем больше и длина априорной траектории $T^d$. Поскольку нам необходим постоянно возбуждающий порядка $n + T$ сигнал $u^d$, то,  как уже отмечалось в Замечании \ref{remark on input length}, для длины $T^d$ этого сигнала справедлива оценка $T^d \geq (n + T)(m + 1) - 1,$ где $m$ --- размерность входа.
\end{remark}

Вместо явного задания динамики системы моделью $(A,B,C,D)$ в пространстве состояний, будем пользоваться неявным описанием  поведения системы в виде (\ref{traj-cond}). Начальное состояние системы также фиксируем неявно, начиная управление в момент $n$.


Таким образом, в каждый момент времени $n \leq \tau \leq T$ решаем следующую задачу оптимального программного управления, обладая неточной траекторией $\{u_\tau^p, \tilde{y}_\tau^p\}$:
\begin{equation}\label{dd-oc-at-tau}
\min\limits_{u(\tau)} u(\tau)^Tu(\tau),
\end{equation}
$$
\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
\end{pmatrix} \alpha(\tau) = \begin{pmatrix}
u_\tau^p \\
y_\tau^p \\
u(\tau) \\
\end{pmatrix},
$$
$$
\tilde{y}_\tau^p = y_\tau^p + \xi_\tau, \quad -\varepsilon\mathbbm{1} \leq \xi_\tau \leq \varepsilon \mathbbm{1},
$$
$$u_{\min}(\tau) \leq u(\tau) \leq u_{\max}(\tau),$$
$$
G_\tau Y_\tau^f \alpha(\tau) \leq g_\tau \quad \forall \alpha(\tau), \xi_\tau,
$$
где матрица
\[
G_\tau =
\begin{pmatrix}
  \begin{matrix}
  G(\tau)
  \end{matrix}
  & \rvline & \bigzero & \rvline & \cdots & \rvline & \bigzero\\
\hline
  \bigzero & \rvline &
  \begin{matrix}
    G(\tau + 1)
  \end{matrix}
  & \rvline & \cdots  & \rvline & \bigzero \\
\hline
  \vdots & \rvline & \vdots & \rvline &
  \begin{matrix}
    \ddots
  \end{matrix}
  & \rvline & \bigzero \\
\hline
  \bigzero & \rvline & \bigzero & \rvline & \bigzero & \rvline &
  \begin{matrix}
    G(T-1)
  \end{matrix}
\end{pmatrix},
\]
вектор $g_{\tau} = (g(\tau), g(\tau+1), \cdots, g(T-1)),$ \\
$u_{\min}(\tau) = (\underbrace{u_{\min}, \ldots, u_{\min}}_{T - \tau \textup{ раз}}), \quad u_{\max}(\tau) = (\underbrace{u_{\max}, \ldots, u_{\max}}_{T - \tau \textup{ раз}}).$

Из полученного в момент $\tau$ оптимального управляющего воздействия $u^*(\tau, u^p_\tau, \tilde{y}^p_\tau) = (u^*(\tau|\tau, u^p_\tau, \tilde{y}^p_\tau), u^*(\tau+1|\tau, u^p_\tau, \tilde{y}^p_\tau), \ldots, u^*(T-1|\tau, u^p_\tau, \tilde{y}^p_\tau))$  применяем к системе $u^p(\tau) := u^*(\tau|\tau, u^p_\tau, \tilde{y}^p_\tau)$. Переходим к решению задачи (\ref{dd-oc-at-tau}) в момент $\tau+1$, зная траекторию $\{u^p_{\tau+1}, \tilde{y}^p_{\tau+1}\}$. Таким образом, если существовало допустимое воздействие в момент $\tau$, то гарантированно существует допустимое воздействие в момент $\tau + 1$, причем значение критерия качества на каждом шагу не увеличивается.

\subsection{Принцип разделимости}

Многообещающим выглядит разделение задач наблюдения и управления, использованное в предыдущей главе. Продемонстрируем, как элегантно реализуется принцип разделимости в бихевиористском подходе.

\begin{lemma}\label{dd-separation}
Пусть $\{u_{\tau}^p, y_{\tau}^p \}$ --- некоторая фиксированная траектория системы (\ref{traj-cond}) длины $\tau \geq n$. Тогда любая траектория $\{u_{\tau}^p, u, y_{\tau}^p, y\}$ длины $T$ системы (\ref{traj-cond}) однозначно представима в виде суммы траекторий $\{0, u, 0, y_0\}$ и $\{u_{\tau}^p, 0, y_{\tau}^p, \hat{y}\}$ длины $T$, причем для фиксированного $u$ определить неизвестные участки $y_0, \hat{y}$ можно следующим образом:\\
1. Найти некоторые решения $\hat{\alpha}, \alpha_0$ алгебраичеких уравнений
\begin{equation}
\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
\end{pmatrix} \hat{\alpha} = \begin{pmatrix}
u_\tau^p \\
y_\tau^p \\
0 \\
\end{pmatrix}, \quad
\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
\end{pmatrix} \alpha_0 = \begin{pmatrix}
0 \\
0 \\
u \\
\end{pmatrix}.
\end{equation}
2. Вычислить $\hat{y} = Y_\tau^f\hat{\alpha}, \quad y_0 = Y_\tau^f\alpha_0$.
\end{lemma}

\begin{proof}
Поскольку длина $\tau$ исходной траектории не меньше размерности системы $n$, то, в силу модификации теоремы \ref{trajectory check}, однозначно определены и могут быть найдены в результате 1-2 выходные сигналы системы $\hat{y}, y_0$ для входных сигналов $0, u$ соответственно. Более того, $\hat{y}$ соответствует выходной траектории неуправляемой с момента $\tau$ системы, а $y_0$ ---  выходному сигналу номинальной системы из нулевого состояния в момент $\tau$. Здесь нулевое состояние в момент $\tau$  неявно задают $\{u_\tau^p, y_\tau^p\} = \{0, 0\}$ --- именно такую траекторию имеет система с нулевым начальным состоянием, а значит, и с нулевым состоянием в момент $ \tau$; с другой стороны, $\tau \geq n$ обеспечивает единственность этой траектории. $\Box$
\end{proof}

В связи с вышеизложенным, ограничение на выходные сигналы принимает вид
$G_{\tau}(y_0(\tau)+\hat{y}(\tau)) \leq g_{\tau}$. Наложим на $y_0(\tau)$ суженное условие:
\begin{equation}\label{tightened constraint}
G_{\tau}y_0(\tau) \leq g_{\tau}-\chi(\tau),
\end{equation}
где каждая компонента $\chi_i(\tau)$ соответствует наихудшей реализации состояния системы в момент $\tau$, а именно является решением задачи линейного программирования
\begin{equation} \label{estimation}
\chi_i(\tau) = \max\limits_{\hat{\alpha}(\tau), \xi_{\tau}, \hat{y}(\tau)} G_{\tau i}\hat{y}(\tau),
\end{equation}
$$\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
Y_\tau^f \\
\end{pmatrix} \hat{\alpha}(\tau) = \begin{pmatrix}
u_\tau^p \\
\tilde{y}_\tau^p + \xi_{\tau}\\
0 \\
\hat{y}(\tau)\\
\end{pmatrix},
$$
$$-\varepsilon \mathbbm{1} \leq \xi_{\tau} \leq \varepsilon \mathbbm{1}.$$
Задача (\ref{estimation}) в компактной формулировке (исключается $\xi_{\tau}$) имеет вид
\begin{equation} \label{estimation-lp}
\chi_i(\tau) = \max\limits_{\hat{\alpha}(\tau)} G_{\tau i}Y_{\tau}^f\hat{\alpha}(\tau),
\end{equation}
$$\begin{pmatrix}
U_\tau^p \\
U_\tau^f \\
\end{pmatrix} \hat{\alpha}(\tau) = \begin{pmatrix}
u_\tau^p \\
0 \\
\end{pmatrix},
$$
$$
\tilde{y}_{\tau}^p-\varepsilon \mathbbm{1} \leq
Y_\tau^p \hat{\alpha} \leq
\tilde{y}_\tau^p + \varepsilon \mathbbm{1}.
$$
Выполнение  для $y_0$ суженного ограничения (\ref{tightened constraint}) очевидно влечет удовлетворение исходного ограничения на $y$ для любой возможной реализации $\hat{y}$.




%\begin{comment}
%\begin{definition}
%\textit{Уровнем ошибки} в задаче \ref{estimation-lp} будем называть $\varepsilon$, а \textit{номинальной задачей наблюдения при уровне ошибки} $\varepsilon$ будем называть задачу \ref{estimation-lp} для истинной траектории, т.е. для случая $\tilde{y}_\tau = y_\tau.$
%\end{definition}
%Очевидно, если задача \ref{estimation-lp} разрешима при любой покомпонентно ограниченной $\varepsilon$ ошибке, то должна быть разрешима номинальная задача. Еще один результат, касающийся вопроса гарантированной разрешимости приведем ниже.
%\begin{lemma}\label{estimation-guarantees}
%Если номинальная задача наблюдения при уровне ошибки $\varepsilon$ разрешима, то для любого неточного выходного сигнала $\tilde{y}_\tau = y_\tau + \xi_\tau$, где ошибка ограничена поэлементно $\norm{\xi_\tau}_\infty \leq \frac{\varepsilon}{2}$ соответствующая задача\ref{estimation-lp} также имеет решение.
%\end{lemma}
%\begin{proof}
%Для любого $\tilde{y}_\tau = y_\tau + \xi_\tau$ с ограниченной ошибкой $\norm{\xi_\tau}_\infty \leq \frac{\varepsilon}{2}$ задача \ref{estimation-lp} имеет те же самые целевую функцию и ограничения в виде равенств, а также не менее сильные ограничивающие неравенства:
%$$y_\tau - \varepsilon \mathbbm{1} \leq \tilde{y}_\tau - \frac{\varepsilon}{2}\mathbbm{1} \leq Y_\tau^p\hat{\alpha} \leq \tilde{y}_\tau + \frac{\varepsilon}{2}\mathbbm{1} \leq y_\tau + \varepsilon \mathbbm{1}.$$
%\end{proof}
%\end{comment}





Детерминированная задача оптимального программного управления с суженными условиями на $y_0$ принимает следующий вид:

\begin{equation}\label{control}
\min\limits_{\alpha_0(\tau), u(\tau), y_0(\tau)}u(\tau)^Tu(\tau),
\end{equation}
$$\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
U_\tau^f \\
Y_\tau^f \\
\end{pmatrix} \alpha_0(\tau) = \begin{pmatrix}
0 \\
0 \\
u \\
y_0(\tau) \\
\end{pmatrix},$$
$$G_{\tau}y_0(\tau) \leq g_{\tau} - \chi(\tau),$$
$$u_{\min}(\tau) \leq u(\tau) \leq u_{\max}(\tau).$$

Снова переходим к эквивалентному, но более компактному виду, получаем
\begin{equation}\label{control-qp}
\min\limits_{\alpha_0(\tau)}\alpha_0(\tau)^T{U_{\tau}^f}^TU_{\tau}^f\alpha_0(\tau),
\end{equation}
$$
\begin{pmatrix}
U_\tau^p \\
Y_\tau^p \\
\end{pmatrix} \alpha_0(\tau) = \begin{pmatrix}
0 \\
0 \\
\end{pmatrix},
$$
$$G_{\tau}Y_{\tau}^f\alpha_0(\tau) \leq g_{\tau} - \chi(\tau),$$
$$u_{\min}(\tau) \leq U_{\tau}^f\alpha_0(\tau) \leq u_{\max}(\tau).$$
Получив решение $\alpha_0^*(\tau, u_\tau^p, \tilde{y}_\tau^p)$ задачи  (\ref{control-qp}), вычисляем оптимальное управление ${u^*(\tau, u_\tau^p, \tilde{y}_\tau^p) = U_\tau^f \alpha_0^*(\tau, u_\tau^p, \tilde{y}_\tau^p)}$. Из вычисленного ${u^*(\tau, u_\tau^p, \tilde{y}_\tau^p) = (u^*(\tau|\tau, u_\tau^p, \tilde{y}_\tau^p), \ldots, u^*(T-1|\tau, u_\tau^p, \tilde{y}_\tau^p))}$ подаем на вход системе ${u^p(\tau) = u^*(\tau|\tau, u_\tau^p, \tilde{y}_\tau^p).}$

\bigskip
Таким образом, задача оптимального управления, решаемая в каждой временной точке $n \leq \tau \leq T-1$, свелась к нескольким задачам линейного программирования и одной выпуклой задаче квадратичного программирования.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Рекуррентная разрешимость}
В данном разделе будут предоставлено теоретическое обоснование реализуемости предложенной схемы. В частности, следующая теорема доказывает рекуррентную разрешимость задач  (\ref{estimation}) и (\ref{control}), решаемых в каждый момент времени $\tau = n, \ldots, T-1$.

В данном разделе используем обозначения предыдущего, лишь будем опускать для краткости траекторию $\{u^p_\tau, \tilde y^p_\tau\}$ --- одну и ту же во всех обозначениях для момента $\tau$, --- как то
$\alpha_0(\tau) = \alpha_0(\tau, u^p_\tau, \tilde y^p_\tau)$,
${u^*(t|\tau) = u^*(t|\tau, u^p_\tau, \tilde y^p_\tau)}$ и все прочие. 
То же касаемо момента ${\tau+1}$ и траектории $\{u^p_\tau, u^*(\tau|\tau), \tilde y^p_\tau, \tilde y^p(\tau)\}$, которая реализуется при подаче управления $u^*(\tau|\tau)$ в момент $\tau$.
Как и ранее, символом $^*$ помечены оптимальные решения. 

\begin{theorem}
Пусть в момент $\tau$ для неточной траектории $\{u^p_\tau, \tilde y^p_\tau\}$ разрешима каждая из задач (\ref{estimation}). Далее, пусть разрешима соответствующая задача (\ref{control}) с параметром $\chi(\tau)$, поставленным решениями задач (\ref{estimation}). Тогда в момент $\tau+1$ для траектории $\{u^p_\tau, u^*(\tau|\tau), \tilde y^p_\tau, \tilde y^p(\tau)\}$ эти задачи также разрешимы. Более того, $\norm{u^*(\tau+1)}^2 \leq \norm{u_{\tau+1}^*(\tau)}^2$, где ${u_{\tau+1}^*(\tau) = (u^*(\tau+1|\tau), \ldots, u^*(T-1|\tau))}$.
\end{theorem}

\begin{proof}
Прежде всего, необходимо доказать разрешимость каждой из задач линейного программирования (\ref{estimation}) при $\tau \coloneqq \tau+1$. Зафиксируем некоторые $\alpha_0^c(\tau+1)$, $y^c_0(\tau+1)$, удовлетворяющие следующим равенствам: 

\begin{equation}\label{alpha_0-candidate}
\begin{pmatrix}
U_{\tau}^p \\
u^d(\tau), u^d(\tau+1), \ldots, u^d(\tau+T^d-T)\\
Y_{\tau}^p \\
y^d(\tau), y^d(\tau+1), \ldots, y^d(\tau+T^d-T)\\
U_{\tau+1}^f \\
\end{pmatrix} \alpha_0^c(\tau+1) = \begin{pmatrix}
0\\
0\\
0\\
0\\
u^*_{\tau+1}(\tau)\\
\end{pmatrix},
\end{equation}
\begin{equation}
Y_{\tau+1}^f \alpha_0^c(\tau+1) = y^c_0(\tau+1).
\end{equation}\label{y_0-c}

Согласно Лемме \ref{dd-separation}, решение $\alpha_0^c(\tau+1)$ для (\ref{alpha_0-candidate}) существует для всех возможных $u^*_{\tau+1}(\tau)$, и этому $\alpha_0^c(\tau+1)$ соответствует $y^c_0(\tau+1)$ ---  выходная траектория, если система движется из состояния $x(\tau+1)=0$ под воздействием хвоста $u^*_{\tau+1}(\tau)$ оптимального управления предыдущего шага схемы.

Далее с помощью значений $\alpha_0^c(\tau+1)$, $y^c_0(\tau+1)$ докажем разрешимость задач оптимального наблюдения. 

Сдвинем переменную $\hat \alpha(\tau+1)$, относительно которой поставлены задачи оптимального наблюдения, на константу, перейдем к новой переменной $\Delta\alpha(\tau+1)$:
$$\hat \alpha(\tau+1) = \alpha_0^*(\tau)-\alpha_0^c(\tau+1)+\Delta\alpha(\tau+1).$$
С учетом того, что для $\alpha_0^*(\tau)$ выполняется
\begin{equation}\label{alpha_0-previous}
\begin{pmatrix}
U_{\tau}^p \\
u^d(\tau), u^d(\tau+1), \ldots, u^d(\tau+T^d-T)\\
Y_{\tau}^p \\
y^d(\tau), y^d(\tau+1), \ldots, y^d(\tau+T^d-T)\\
U_{\tau+1}^f \\
\end{pmatrix} \alpha_0^*(\tau) = \begin{pmatrix}
0\\
u^*(\tau|\tau)\\
0\\
y_0^*(\tau|\tau)\\
u^*_{\tau+1}(\tau)\\
\end{pmatrix},
\end{equation}
\begin{equation}\label{alpha_0-previous-y}
Y_{\tau+1}^f \alpha_0^*(\tau) = y^*_{0, \tau +1}(\tau+1),
\end{equation}
а $\alpha_0^c(\tau+1)$ удовлетворяет (\ref{alpha_0-candidate}), (\ref{y_0-c}), из задач для определения $\chi(\tau+1)$, поставленных для $\hat \alpha(\tau+1)$, получаем следующие эквивалентные задачи относительно переменной $\Delta\alpha(\tau+1)$: 
\begin{equation} \label{estimation-delta-alpha}
\chi_i(\tau+1) = G_{(\tau+1)i}(y_{0, \tau+1}^*(\tau) - y_0^c(\tau+1)) +\max\limits_{\Delta\alpha(\tau+1)} G_{(\tau+1) i}Y_{\tau+1}^f\Delta\alpha(\tau+1),
\end{equation}

\begin{equation}\label{u-delta-alpha}
\begin{pmatrix}
U_\tau^p \\
u(\tau), u(\tau+1), \ldots, u(\tau+T^d-T)\\
U_\tau^f \\
\end{pmatrix} \Delta\alpha(t+1) = \begin{pmatrix}
u_\tau^p \\
0 \\
0\\
\end{pmatrix},
\end{equation}

\begin{equation}\label{y-delta-alpha}
\tilde{y}_{\tau}^p-\varepsilon \mathbbm{1}  \leq
Y_\tau^p \Delta \alpha(t+1)
\leq \tilde{y}_\tau^p + \varepsilon \mathbbm{1},
\end{equation}

\begin{equation}\label{estimation-new-constraint}
\begin{split}
\tilde y^p(\tau)-y_0^*(\tau|\tau) - \varepsilon \mathbbm{1} & \leq
\begin{pmatrix}
y^d(\tau), y^d(\tau+1),\ldots, y^d(\tau+T^d-T)
\end{pmatrix} \Delta \alpha(t+1) \leq \\
& \leq \tilde y^p(\tau)-y_0^*(\tau|\tau) +  \varepsilon \mathbbm{1}.
\end{split}
\end{equation}

Сравним задачи (\ref{estimation-delta-alpha}) для $\Delta \alpha(\tau + 1)$ и (\ref{estimation-lp}) для $\hat \alpha (\tau)$. 
На $\Delta \alpha(\tau+1)$ наложено дополнительное ограничение (\ref{estimation-new-constraint}), а целевые функции разнятся на константу. 

Множество допустимых решений $\Delta \alpha(\tau+1)$ непустое. Его элементом является $\hat\alpha^p(\tau+1)$, соответствующий истинной траектории $\{u^p_\tau, 0, y^p_\tau, \hat y^p(\tau|\tau)\}$ согласно Лемме \ref{dd-separation}:
\begin{equation}\label{alpha_true}
\begin{pmatrix}
U_{\tau}^p \\
u^d(\tau), u^d(\tau+1), \ldots, u^d(\tau+T^d-T)\\
Y_{\tau}^p \\
y^d(\tau), y^d(\tau+1), \ldots, y^d(\tau+T^d-T)\\
U_{\tau+1}^f \\
\end{pmatrix} \hat\alpha^p(\tau+1) = \begin{pmatrix}
u^p_\tau\\
0\\
y^p_\tau\\
\hat y^p(\tau)\\
0\\
\end{pmatrix}.
\end{equation}
Действительно, для $\hat\alpha^p(\tau+1)$ ограничения (\ref{u-delta-alpha}), (\ref{y-delta-alpha}) очевидно удовлетворены, а (\ref{estimation-new-constraint}) выполняется ввиду того, что по принципу разделимости $y^p(\tau) = y_0^*(\tau|\tau) + \hat y^p(\tau|\tau)$.
%тут пояснить про $\hat y^p(\tau|\tau)$ подробнее?

Поскольку множество допустимых решений $\hat \alpha(\tau)$ включает в себя множество допустимых решений $ \Delta \alpha (\tau+1)$, и последнее не пусто, из существования оптимального решения $\hat \alpha^*(\tau)$ следует существование оптимального решения $\Delta \alpha^*(\tau+1)$, причем с учетом сдвига на константу целевой функции справедлива следующая оценка: 
\begin{equation}\label{chi-bound}
\chi(\tau+1) \leq G_{\tau+1}y_{0, \tau+1}^*(\tau) - G_{\tau+1}y_0^c(\tau+1) + \chi_{\tau+1}(\tau)
\end{equation}

Итак, разрешимость задач оптимального оценивания доказана. Остается продемонстрировать, что множество допустимых решений $\alpha_0(\tau+1)$ в задаче оптимального управления (\ref{control-qp}) при $\tau \coloneqq \tau+1$ непусто --- тогда эта выпуклая задача квадратичного программирования имеет решение. Покажем, что $\alpha_0^c(\tau+1)$ --- допустимое решение. Уже по построению $\alpha_0^c(\tau+1)$ выполнены все условия, кроме условий на выходной сигнал $y_0^c(\tau+1)$: 
\begin{equation}\label{y_0-c-constraint}
G_{\tau+1} y_0^c(\tau+1) \leq g_{\tau+1}-\chi(\tau+1).
\end{equation}
С учетом (\ref{chi-bound}) и (\ref{alpha_0-previous-y}) получаем
\begin{equation*}
\begin{split}
G_{\tau+1} y_0^c(\tau+1) + \chi(\tau+1) & \leq G_{\tau+1} y_0^c(\tau+1) + \\
& + G_{\tau+1} y_{0, \tau+1}^*(\tau) - G_{\tau+1}y_0^c(\tau+1) + \chi_{\tau+1}(\tau) = \\
& = G_{\tau+1}y_{0, \tau+1}^*(\tau) + \chi_{\tau+1}(\tau) \leq g_{\tau+1},
\end{split}
\end{equation*}
что доказывает (\ref{y_0-c-constraint}).
Наконец, поскольку решение $\alpha_0^c(\tau+1)$ допустимо, $$\norm{u^*(\tau+1)}^2 \leq \alpha_0^c(\tau+1)^T (U_{\tau+1}^f)^T U_{\tau+1}^f \alpha_0^c(\tau+1) = \norm{u^*_{\tau+1}(\tau)}^2,$$ что завершает доказательство всех пунктов теоремы.
%мб разбить утверждения теоремы на i, ii, ...?
$\Box$
\end{proof}

\begin{corollary}
Если задачи оптимального оценивания (\ref{estimation}) и управления (\ref{control}) разрешимы в начальный момент времени $\tau=n$, то они разрешимы и в каждый из последующих моментов $\tau = n+1, \ldots, T-1$. При этом значение критерия качества $\tau$ 
$$J(\tau) = \sum\limits_{t=0}^{\tau-1}\norm{u^p(t)}^2 + \sum\limits_{t=\tau}^{T-1}\norm{u^*(t|\tau, u^p_\tau, \tilde y^p_\tau)}^2$$
является невозрастающей функцией.
\end{corollary}

Доказательство теоремы экстенсивно использует хвост $u_{\tau+1}^*(\tau)$ оптимального управления, полученного в предыдущей временной точке: не только стандартно, для текущей задачи оптимального управления, но и для предшествующего доказательства разрешимости задач оптимального оценивания. Это позволяет учесть взаимосвязь не только между соответствующими задачами предыдущего и текущего момента, но и между самими задачами текущего момента. В частности, помимо обоснования разрешимости, для задач оптимального оценивания приводится такая верхняя оценка решения $\chi(\tau+1)$, которая позже позмолит продемонстрировать допустимость управления $u_{\tau+1}^*(\tau)$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Недетерминированный случай: априорные измерения неточны}
В этом разделе будет кратко приведена идея развития результатов.
Интерес представляет случай, когда и априорные измерения содержат некоторую ошибку, т.е. $\tilde{y}^d = y^d + \xi^d.$

Тогда $\tilde{Y}_{\tau}^p = Y_{\tau}^p + \mathit{\Xi}_{\tau}^p$,
$\tilde{Y}_{\tau}^f = Y_{\tau}^f + \mathit{\Xi}_{\tau}^f$, где
$$
\begin{pmatrix}
		\mathit{\Xi}_{\tau}^p\\
		\mathit{\Xi}_{\tau}^f
		\end{pmatrix}  = \begin{pmatrix}
  \xi(0) & \cdots & \xi(T^d-T)\\
  \vdots & \ddots & \vdots \\
  \xi(\tau-1) & \cdots & \xi(\tau - 1 + T^d-T) \\
  \hline
  \xi(\tau) & \cdots & \xi(\tau + T^d-T)\\
  \vdots & \ddots & \vdots \\
  \xi(T-1) & \cdots & \xi(T^d-1)
\end{pmatrix}
    = H_T(\xi^d).
$$

В соответствии с этим задача оптимального оценивания (\ref{estimation}) перепишется следующим образом:

\begin{equation} \label{estimation-noisy}
\chi_i(\tau) = \max\limits_{\hat{\alpha}, \xi_{\tau}, \xi^d} G_{\tau i}\hat{y},
\end{equation}
$$\begin{pmatrix}
U_\tau^p \\
Y_\tau^p + \mathit{\Xi}_\tau^p\\
U_\tau^f \\
Y_\tau^f + \mathit{\Xi}_\tau^f \\
\end{pmatrix} \hat{\alpha} = \begin{pmatrix}
u_\tau^p \\
\tilde{y}_\tau^p + \xi_{\tau}\\
0 \\
\hat{y}\\
\end{pmatrix},
$$
$$-\varepsilon \mathbbm{1} \leq \xi_{\tau} \leq \varepsilon \mathbbm{1},$$
$$-\varepsilon \mathbbm{1} \leq \xi^d \leq \varepsilon \mathbbm{1}.$$

Задача (\ref{estimation-noisy}) представяет собой задачу с квадратичной целевой функцией и квадратичными ограничениями относительно переменной $(\hat{\alpha}, \xi^d)$. Сложность заключается в том, данная задача является невыпуклой. В дальнейшем было бы интересно исследовать эффективные способы решения этой невыпуклой задачи оптимального оценивания. Впоследствии можно использовать этот результат для решения соответствующей задачи оптимального управления в условии неточной априорной траектории.

\bigskip
В данной главе был предложен новый способ решения задачи, поставленной в предыдущей главе. Этот способ не требует знания реализации системы в пространстве состояний. Предложенный метод сводится к решению задач линейного и квадратичного программирования, базирующихся лишь на двух траекториях системы: априорной и наблюдаемой в процессе управления.

Доказано, что если в начальный момент управления эти задачи линейного и квадратичного программирования разрешимы, то соответсвующие задачи разрешимы и в каждый последующий момент, при этом значение критерия качества гарантированно не возрастает. 

Задача решена в предположении, что траектория, измеряемая в процессе управления, неточна, но априорная траектория известна точно. Было предложено дальнейшее направление исследования: случай, когда априорная траектория также зашумлена. 